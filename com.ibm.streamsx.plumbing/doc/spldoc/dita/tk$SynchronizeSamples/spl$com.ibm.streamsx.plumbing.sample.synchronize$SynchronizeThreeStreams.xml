<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="spldoc_compilationunit">
<title>SPL File <tt>SynchronizeThreeStreams.spl</tt></title>
<refbody>
<section>
<p>
<xref href="../toolkits/toolkits.xml">streamsx.plumbing</xref> &gt; <xref href="tk$SynchronizeSamples.xml">SynchronizeSamples 1.0.0</xref> &gt; <xref href="ns$com.ibm.streamsx.plumbing.sample.synchronize.xml">com.ibm.streamsx.plumbing.sample.synchronize</xref> &gt; SynchronizeThreeStreams.spl</p>
</section>
<section>
  <title outputclass="splhead-1">Content</title>
  <dl>
    <dlentry><dt></dt><dd></dd></dlentry>
    <dlentry>
      <dt outputclass="splhead-2">Operators</dt>
      <dd>
<sl>
<sli><b><xref href="spl$com.ibm.streamsx.plumbing.sample.synchronize$SynchronizeThreeStreams.xml#spldoc_compilationunit/composite_operator__SynchronizeThreeStreams">SynchronizeThreeStreams</xref></b>: This sample application for the Synchronize operator reads three pre-recorded streams from three files.
</sli>
</sl>
      </dd>
    </dlentry>
    <dlentry>
      <dt outputclass="splhead-2">Functions</dt>
      <dd>
<sl>
<sli><b><xref href="spl$com.ibm.streamsx.plumbing.sample.synchronize$SynchronizeThreeStreams.xml#spldoc_compilationunit/function__SecondsToTimestamp.float64">SecondsToTimestamp(float64)</xref></b>
</sli>
</sl>
      </dd>
    </dlentry>
  </dl>
</section>
<section>
  <title outputclass="splhead-1">Composites</title>
</section>
<section id="composite_operator__SynchronizeThreeStreams">
  <title outputclass="splpart">public composite SynchronizeThreeStreams</title>
</section>
<section>

<p>This sample application for the Synchronize operator reads three pre-recorded streams from three files. Two files contain phrases of text from the audio tracks of several short videos, as transcribed by two speech recognition engines. The third file contains phrases of text from the subtitle track of one of the videos. Each tuple created from each line of each file includes the starting time of each phrase, relative to the beginning of its video, and duration of the phrase in the video. Punctuation is manually inserted into the streams at the end of each video's phrases.
</p>
<p>The Synchronize operator uses the starting times to synchronize the three streams, which are merged into a single transcript, with each stream's phrases in a separate column, annotated with their starting times and durations.
</p>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
  <title outputclass="splhead-2">Composite Operator Graph</title>
</section>
<section outputclass="splgraph">
  <image href="../../image/tk$SynchronizeSamples/op$com.ibm.streamsx.plumbing.sample.synchronize$SynchronizeThreeStreams.svg" width="552" height="198">
    <alt>SPL composite operator image not displayed. Problem loading file: ../../image/tk$SynchronizeSamples/op$com.ibm.streamsx.plumbing.sample.synchronize$SynchronizeThreeStreams.svg
</alt>
  </image>
</section>
<section>
  <title outputclass="splhead-2">SPL Source Code</title>
</section>

<section>
   <codeblock>
<![CDATA[
 composite SynchronizeThreeStreams {
 
 	type PhraseType =  
 		rstring outputDirectory, 
 		rstring outputFilename, 
 		rstring indention,
 		rstring phrase, 
 		float64 start, 
 		float64 duration ;
 	
 	graph 
 
     // read stream of phrases from first speech recognition engine and insert punctuation between videos
 	
 	stream<PhraseType> Speech1Stream = FileSource() { param file: "sync4.Speech1PhraseStream.in"; format: csv; }
 	
 	stream<PhraseType> PunctuatedSpeech1Stream = Punctor(Speech1Stream) {
 	param punctuate: outputDirectory=="WindowMarker"; position: after; }
 	
 	stream<PhraseType> IndentedPunctuatedSpeech1Stream as Out1 = Functor(PunctuatedSpeech1Stream as Out) {
 	param filter: outputDirectory!="WindowMarker"; 
 	output Out1: indention = ""; }
 
 
     // read stream of phrases from second speech recognition engine, add indention, and insert punctuation between videos
 	
 	stream<PhraseType> Speech2Stream = FileSource() { param file: "sync4.Speech2PhraseStream.in"; format: csv; }
 	
 	stream<PhraseType> PunctuatedSpeech2Stream = Punctor(Speech2Stream) {
 	param punctuate: outputDirectory=="WindowMarker"; position: after; }
 	
 	stream<PhraseType> IndentedPunctuatedSpeech2Stream as Out2 = Functor(PunctuatedSpeech2Stream) {
 	param filter: outputDirectory!="WindowMarker"; 
 	output Out2: indention = "\t\t\t\t"; }
 	
 
     // read stream of phrases from subtitle track of one video, add more indention, and insert punctuation between videos
 
 	stream<PhraseType> SubtitleStream = FileSource() { param file: "sync4.SubtitleStream.in"; format: csv; }
 	
 	stream<PhraseType> PunctuatedSubtitleStream = Punctor(SubtitleStream) {
 	param punctuate: outputDirectory=="WindowMarker"; position: after; }
 	
 	stream<PhraseType> IndentedPunctuatedSubtitleStream as OutT = Functor(PunctuatedSubtitleStream) {
 	param filter: outputDirectory!="WindowMarker"; 
 	output OutT: indention = "\t\t\t\t\t\t\t\t"; }
 	
     // synchronize all three streams
 	
 	( stream<PhraseType> SynchronizedSpeech1Stream ;
 	  stream<PhraseType> SynchronizedSpeech2Stream ;
 	  stream<PhraseType> SynchronizedSubtitleStream ) = com.ibm.streamsx.plumbing.synchronize::Synchronize( 
                                                             IndentedPunctuatedSpeech1Stream as In1; 
                                                             IndentedPunctuatedSpeech2Stream as In2; 
                                                             IndentedPunctuatedSubtitleStream as InT) {
 	param 
 		timeAttributes: In1.start, In2.start, InT.start; 
 		timeFactor: 0.0; // replay as fast as possible
 	config threadedPort: 
 		queue(In1, Sys.DropFirst, 1000),
 		queue(In2, Sys.DropFirst, 1000),
 		queue(InT, Sys.DropFirst, 1000); }	
 
     // merge synchronized streams into a single transcript
 
 	() as Transcript = Custom(SynchronizedSpeech1Stream, SynchronizedSpeech2Stream, SynchronizedSubtitleStream as In) {
 	logic state: {
 		rstring filename = dataDirectory() + "/SynchronizeThreeStreams.transcript.out";
 		mutable uint64 file = 0; }
 	onTuple In: {	
 		mutable int32 error = 0;	
 		if (file==0ul) { 
  			file = fopen(filename , "w", error); 
 			assert(error==0, "sorry, could not open '" + filename + "', " + strerror(error)); }
 		if (length(phrase)>0) {
 			rstring timeline = indention + "at " + SecondsToTimestamp(start) + " for " + formatNumber(duration,1u,3u,false) + " seconds:\n";
 			rstring textline = indention + phrase + "\n\n";
 			fwriteString(timeline+textline, file, error);
 			assert(error==0, "sorry, could not write to '" + filename + "', " + strerror(error)); } }
 	onPunct In: {
 		mutable int32 error = 0;
 		if (file!=0ul) {	
 		fwriteString("------------------------\t------------------------\t------------------------\n", file, error);
 		if (currentPunct()==Sys.FinalMarker) { fclose(file, error); } } }
 	} 
 
 
     // log intermediate streams when debugging
 
 //  () as Speech1Sink = FileSink(Speech1Stream) { param file: "debug.SynchronizeThreeStreams.Speech1Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as PunctuatedSpeech1Sink = FileSink(PunctuatedSpeech1Stream) { param file: "debug.SynchronizeThreeStreams.PunctuatedSpeech1Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as IndentedPunctuatedSpeech1Sink = FileSink(IndentedPunctuatedSpeech1Stream) { param file: "debug.SynchronizeThreeStreams.IndentedPunctuatedSpeech1Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //	() as Speech2Sink = FileSink(Speech2Stream) { param file: "debug.SynchronizeThreeStreams.Speech2Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as PunctuatedSpeech2Sink = FileSink(PunctuatedSpeech2Stream) { param file: "debug.SynchronizeThreeStreams.PunctuatedSpeech2Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as IndentedPunctuatedSpeech2Sink = FileSink(IndentedPunctuatedSpeech2Stream) { param file: "debug.SynchronizeThreeStreams.IndentedPunctuatedSpeech2Stream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as SubtitleSink = FileSink(SubtitleStream) { param file: "debug.SynchronizeThreeStreams.SubtitleStream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as PunctuatedSubtitleSink = FileSink(PunctuatedSubtitleStream) { param file: "debug.SynchronizeThreeStreams.PunctuatedSubtitleStream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as IndentedPunctuatedSubtitleSink = FileSink(IndentedPunctuatedSubtitleStream) { param file: "debug.SynchronizeThreeStreams.IndentedPunctuatedSubtitleStream.out"; format: txt; flush: 1u; writePunctuations: true; }
 //  () as SyncSink = FileSink(SynchronizedSpeech1Stream, SynchronizedSpeech2Stream, SynchronizedSubtitleStream) { param file: "debug.SynchronizeThreeStreams.SyncStreams.out"; format: txt; flush: 1u; writePunctuations: true; }
 
 
 }
]]>
   </codeblock>
</section>
<section>
  <title outputclass="splhead-1">Functions</title>
</section>
<section id="function__SecondsToTimestamp.float64">
  <title outputclass="splpart">rstring SecondsToTimestamp(float64 elapsed)</title>
</section><section>
<title>Parameters</title>
 <sl>
   <sli>
<b>elapsed</b>
   </sli>
 </sl>
</section>
<section>
<title>Returns</title>
<sl><sli>
<tt>rstring</tt>
</sli></sl>
</section>
<section>
  <title outputclass="splhead-2">SPL Source Code</title>
</section>
<section>
   <codeblock>
<![CDATA[
 rstring SecondsToTimestamp(float64 elapsed) { 
 	
 	int32 hours = (int32)(elapsed/3600.0);
 	int32 minutes = (int32)((elapsed-(float64)hours*3600.0)/60.0);
 	int32 seconds = (int32)(fmod(elapsed, 60.0));
 	int32 milliseconds = (int32)(fmod(elapsed, 1.0)*1000.0);
 	
 	return (rstring)minutes + ":" + 
 		   (seconds<10 ? "0" : "") + (rstring)seconds + "." + 
 		   (milliseconds<100 ? "0" : "") + (milliseconds<10 ? "0" : "") + (rstring)milliseconds ; 
 }
]]>
   </codeblock>
</section>
</refbody>
</reference>

